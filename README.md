# Customer Churn Prediction

## ğŸ“Œ Description
This project is part of the **Udacity MLOps Engineer Nanodegree â€“ February 2025**.

The goal is to **refactor** the existing notebook (`src/notebooks/churn_notebook.ipynb`) by applying **clean code best practices** and improving modularity.  
For implementation details, refer to `src/notebooks/Guide.jpynb`.

### ğŸ”¹ **Key Features**
âœ” **PEP 8 compliant & well-documented**  
âœ” **Modular, maintainable, and reusable ML pipeline**  
âœ” **Flexible configuration via `config/config.json`**  
âœ” **Stores EDA plots, trained models, and evaluation metrics**  
âœ” **Efficient handling of categorical variables**  

---

## ğŸ“‚ **Project Structure**
## Project Structure

```
customer_churn/                     Main project directory
â”‚â”€â”€ README.md                       Project documentation
â”‚â”€â”€ requirements.txt                Dependencies
â”‚â”€â”€ config/                         Configuration files
â”‚   â”œâ”€â”€ config.json                 Main configuration file
â”‚   â”œâ”€â”€ preprocessing_config.json
â”‚   â”œâ”€â”€ data_splitting_profiles.json
â”‚   â”œâ”€â”€ training_config.json
â”‚â”€â”€ data/                           Dataset storage
â”‚   â”œâ”€â”€ raw/                        Original data
â”‚   â”‚   â”œâ”€â”€ bank_data.csv
â”‚   â”œâ”€â”€ processed/                  Preprocessed data
â”‚â”€â”€ logs/                           Logging output
â”‚   â”œâ”€â”€ customer_churn.log
â”‚â”€â”€ models/                         Trained models
â”‚   â”œâ”€â”€ LogisticRegression.pkl
â”‚   â”œâ”€â”€ RandomForestClassifier.pkl
â”‚â”€â”€ results/                        Evaluation results
â”‚   â”œâ”€â”€ images/                     Plots and visualizations
â”‚   â”‚   â”œâ”€â”€ eda/                    Exploratory Data Analysis
â”‚   â”œâ”€â”€ json/                       Evaluation metrics
â”‚â”€â”€ src/                            Source code
â”‚   â”œâ”€â”€ churn_library.py            Main ML pipeline
â”‚   â”œâ”€â”€ config_manager.py           Configuration handler
â”‚   â”œâ”€â”€ logger_config.py            Logging setup
â”‚   â”œâ”€â”€ common/                     Shared utilities
â”‚   â”‚   â”œâ”€â”€ exceptions.py           Custom exceptions
â”‚   â”œâ”€â”€ data_preprocessing/         Data cleaning & encoding
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py
â”‚   â”‚   â”œâ”€â”€ data_encoder.py
â”‚   â”œâ”€â”€ eda/                        Exploratory Data Analysis
â”‚   â”‚   â”œâ”€â”€ eda_visualizer.py
â”‚   â”œâ”€â”€ models/                     Model training & evaluation
â”‚   â”‚   â”œâ”€â”€ data_splitter.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â”œâ”€â”€ model_evaluator.py
â”‚   â”œâ”€â”€ notebooks/                  Jupyter notebooks, provided as reference
â”‚   â”‚   â”œâ”€â”€ Guide.ipynb
â”‚   â”‚   â”œâ”€â”€ churn_notebook.ipynb
â”‚â”€â”€ tests/                          Unit tests using pytest
â”‚   â”œâ”€â”€ test_data_cleaner.py
â”‚   â”œâ”€â”€ test_data_encoder.py
â”‚   â”œâ”€â”€ test_data_splitter.py
â”‚   â”œâ”€â”€ test_data_visualizer.py
â”‚   â”œâ”€â”€ test_model_trainer.py
â”‚   â”œâ”€â”€ test_model_evaluator.py
â”‚â”€â”€ utils/                          Utility scripts
â”‚   â”œâ”€â”€ pylint_checker.py           automatically generates a pylint report for all source code

```
---

## âš™ **Installation**
### ğŸ‘… **1. Clone the repository**
```bash
git clone https://github.com/Marcennaji/customer_churn.git
cd customer_churn
```
### ğŸ“¦ **2. Install dependencies**
```bash
pip install -r requirements.txt
```

---

## ğŸš€ **Usage**
### **1. Configure the pipeline**
- Open `config/config.json` in the root directory  
- Set the `"data_path"` to your dataset location  
- To enable **evaluation-only mode**, set:
  ```json
  "eval_only": true
  ```

### **2. Run the ML pipeline**
```bash
python src/churn_library.py --config=config/config.json
```

---

## ğŸ›  **Running Tests**
### **Run all unit tests**
```bash
pytest
```
### **Run tests with verbose output**
```bash
pytest -v
```
- All test files are located in the `tests/` directory  
- Test configuration is managed via `pytest.ini`  

---

## ğŸ“ **Logging & Debugging**
### **Check Logs**
```bash
cat logs/customer_churn.log
```
- Logs include **both info and error messages**
- Stored in `customer_churn.log` after script execution.

---

## ğŸ” **Code formatting and linting**

To ensure high-quality and maintainable code, this project follows strict formatting and linting guidelines.

### Formatting

Instead of `autopep8` and `pylint`, this project uses `black` and `ruff` for code formatting and linting, as configured in `.pre-commit-config.yaml`. The reasons for this choice:

- **black**: Provides consistent, opinionated formatting, ensuring uniformity across all scripts.
- **ruff**: A fast Python linter and formatter, which also provides additional checks and optimizations beyond `black`.

#### autopep8 vs. black

Both autopep8 and black format Python code, but:
autopep8: Focuses on fixing PEP 8 violations (less opinionated).
black: Enforces a strict, opinionated style (makes all code look uniform).
black is the better choice for standardization and team projects.

#### pylint vs. ruff

Both pylint and ruff check for code style and quality, but:
pylint: More thorough but slow and sometimes overly strict.
ruff: Faster, supports many pylint rules, and can auto-fix some issues.
ruff is a modern alternative to pylint, often preferred for speed.

However, for those who want a pylint report, a dedicated script, `pylint_checker.py`, is provided to analyze all Python files recursively and generate both a summary and a detailed report.
Simply run:

```bash
python utils/pylint_checker.py
```
---

## ğŸ“Š **Stored Images & Models**
### âœ… **EDA Plots (Saved in `results/images/eda`)**
âœ” **Univariate (quantitative)** â†’ `histogram_age.png`  
âœ” **Univariate (categorical)** â†’ `bar_chart_marital_status.png`  
âœ” **Bivariate Plot** â†’ `correlation_heatmap.png`

### âœ… **Evaluation Plots (Saved in `results/images/`)**
âœ” **ROC Curves** â†’ `roc_curve.png`  
âœ” **Feature Importances** â†’ `feature_importance_RandomForestClassifier.png`  
âœ” **SHAP Explanation** â†’ `shap_RandomForestClassifier.png`

### âœ… **Stored Models (`models/` Directory)**
âœ” **Logistic Regression (`LogisticRegression.pkl`)**  
âœ” **Random Forest (`RandomForestClassifier.pkl`)**  

Models are stored in **.pkl format using Joblib** for easy deployment.

---

## ğŸ”¬ **Handling Categorical Variables**
- Uses **mean encoding** or **one-hot encoding** based on configuration  
- Efficiently processes categorical columns via **looping**  
- Defined in `src/data_preprocessing/data_encoder.py`

---

## ğŸ›  **Future Improvements**
âœ” **Optimize hyperparameter tuning strategy**  
âœ” **Enhance model versioning with MLflow**  
âœ” **Add Docker support for easy deployment**  

---

## ğŸ‘¨â€ğŸ’¼ **Author**
**Marc Ennaji**  
ğŸŒ [GitHub](https://github.com/Marcennaji) | ğŸ“ [LinkedIn](https://linkedin.com/in/marcennaji)  

---

## ğŸ **License**
This project is licensed under the **MIT License**.  

