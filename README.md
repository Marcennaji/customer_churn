# Customer Churn Prediction

## ğŸ“Œ Description
This project is part of the **Udacity MLOps Engineer Nanodegree â€“ February 2025**.

The goal is to **refactor** the existing notebook (`src/notebooks/churn_notebook.ipynb`) by applying **clean code best practices** and improving modularity.  
For implementation details, refer to `src/notebooks/Guide.jpynb`.

### ğŸ”¹ **Key Features**
âœ” **PEP 8 compliant & well-documented**  
âœ” **Modular, maintainable, and reusable ML pipeline**  
âœ” **Flexible configuration via `config/config.json`**  
âœ” **Stores EDA plots, trained models, and evaluation metrics**  
âœ” **Efficient handling of categorical variables**  

---

## ğŸ“‚ **Project Structure**
## Project Structure

```
customer_churn/                     Main project directory
â”‚â”€â”€ README.md                       Project documentation
â”‚â”€â”€ requirements.txt                Dependencies
â”‚â”€â”€ config/                         Configuration files
â”‚   â”œâ”€â”€ config.json                 Main configuration file
â”‚   â”œâ”€â”€ preprocessing_config.json
â”‚   â”œâ”€â”€ data_splitting_profiles.json
â”‚   â”œâ”€â”€ training_config.json
â”‚â”€â”€ data/                           Dataset storage
â”‚   â”œâ”€â”€ raw/                        Original data
â”‚   â”‚   â”œâ”€â”€ bank_data.csv
â”‚   â”œâ”€â”€ processed/                  Preprocessed data
â”‚â”€â”€ logs/                           Logging output
â”‚   â”œâ”€â”€ customer_churn.log
â”‚â”€â”€ models/                         Trained models
â”‚   â”œâ”€â”€ LogisticRegression.pkl
â”‚   â”œâ”€â”€ RandomForestClassifier.pkl
â”‚â”€â”€ results/                        Evaluation results
â”‚   â”œâ”€â”€ images/                     Plots and visualizations
â”‚   â”‚   â”œâ”€â”€ eda/                    Exploratory Data Analysis
â”‚   â”œâ”€â”€ json/                       Evaluation metrics
â”‚â”€â”€ src/                            Source code
â”‚   â”œâ”€â”€ churn_library.py            Main ML pipeline
â”‚   â”œâ”€â”€ config_manager.py           Configuration handler
â”‚   â”œâ”€â”€ logger_config.py            Logging setup
â”‚   â”œâ”€â”€ common/                     Shared utilities
â”‚   â”‚   â”œâ”€â”€ exceptions.py           Custom exceptions
â”‚   â”œâ”€â”€ data_preprocessing/         Data cleaning & encoding
â”‚   â”‚   â”œâ”€â”€ data_cleaner.py
â”‚   â”‚   â”œâ”€â”€ data_encoder.py
â”‚   â”œâ”€â”€ eda/                        Exploratory Data Analysis
â”‚   â”‚   â”œâ”€â”€ eda_visualizer.py
â”‚   â”œâ”€â”€ models/                     Model training & evaluation
â”‚   â”‚   â”œâ”€â”€ data_splitter.py
â”‚   â”‚   â”œâ”€â”€ model_trainer.py
â”‚   â”‚   â”œâ”€â”€ model_evaluator.py
â”‚   â”œâ”€â”€ notebooks/                  Jupyter notebooks, provided as reference
â”‚   â”‚   â”œâ”€â”€ Guide.ipynb
â”‚   â”‚   â”œâ”€â”€ churn_notebook.ipynb
â”‚â”€â”€ tests/                          Unit tests using pytest
â”‚   â”œâ”€â”€ test_data_cleaner.py
â”‚   â”œâ”€â”€ test_data_encoder.py
â”‚   â”œâ”€â”€ test_data_splitter.py
â”‚   â”œâ”€â”€ test_data_visualizer.py
â”‚   â”œâ”€â”€ test_model_trainer.py
â”‚   â”œâ”€â”€ test_model_evaluator.py
â”‚â”€â”€ utils/                          Utility scripts
â”‚   â”œâ”€â”€ pylint_checker.py           automatically generates a pylint report for all source code

```
---

## âš™ **Installation**
### ğŸ‘… **1. Clone the repository**
```bash
git clone https://github.com/Marcennaji/customer_churn.git
cd customer_churn
```
### ğŸ‘… **2. Setting Up a Virtual Environment (Recommended)**

To ensure a consistent and isolated development environment, it is recommended to use a **Python virtual environment** (`venv`). This prevents conflicts with global Python packages and ensures compatibility across different systems.

#### **Check Python Version**
This project is tested with **Python 3.10**. You can check your version by running:
```bash
python --version
```
If itâ€™s not Python 3.10, install it from [python.org](https://www.python.org/downloads/) or using your systemâ€™s package manager. 

#### **Create and Activate a Virtual Environment**
##### **On macOS & Linux**
```bash
python3 -m venv venv
source venv/bin/activate
```
##### **On Windows**
```powershell
py -3.10 -m venv venv
venv\Scripts\activate
```
Once activated, you should see `(venv)` in your terminal prompt, indicating that you are inside the virtual environment.
Verify that it uses python 3.10.
```bash
python --version
```

Using a virtual environment ensures a clean, conflict-free workspace for developing and running the project. ğŸš€

### ğŸ‘… **3. Install Dependencies**
After activating the virtual environment, install the required dependencies:
```bash
pip install -r requirements.txt
```
---

## ğŸš€ **ML pipeline usage**
### **1. Configure the pipeline**
- Open `config/config.json` and set your root directory:
```json
  "root_directory": "path/to/customer_churn"
  ``` 
- To enable **evaluation-only mode**, if you already have trained models in your `models` directory, set:
  ```json
  "eval_only": true
  ```

### **2. Run the ML pipeline**
```bash
python src/churn_library.py --config=config/config.json
```

---

## ğŸ›  **Running Tests**
### **Run all unit tests**
```bash
pytest
```
### **Run tests with verbose output**
```bash
pytest -v
```
- All test files are located in the `tests/` directory  
- Test configuration is managed via `pytest.ini`  

---

## ğŸ“ **Logging & Debugging**
### **Check Logs**
```bash
cat logs/customer_churn.log
```
- Logs include **both info and error messages**
- Stored in `customer_churn.log` after script execution.

---

## ğŸ” **Code formatting and linting**

To ensure high-quality and maintainable code, this project follows strict formatting and linting guidelines.

Instead of `autopep8` and `pylint`, this project uses `black` and `ruff` for code formatting and linting, as configured in `.pre-commit-config.yaml`. The reasons for this choice:
- **black**: Provides consistent, opinionated formatting, ensuring uniformity across all scripts.
- **ruff**: A fast Python linter and formatter, which also provides additional checks and optimizations beyond `black`.

However, for those who still want a pylint report, a dedicated script, `pylint_checker.py`, is provided as a convenience tool, to analyze all Python files recursively and generate both a summary and a detailed report.
Simply run:
```bash
python utils/pylint_checker.py
```
---

## ğŸ“Š **Stored Images & Models**
### âœ… **EDA Plots (Saved in `results/images/eda`)**
âœ” **Univariate (quantitative)** â†’ `histogram_age.png`  
âœ” **Univariate (categorical)** â†’ `bar_chart_marital_status.png`  
âœ” **Bivariate Plot** â†’ `correlation_heatmap.png`

### âœ… **Evaluation Plots (Saved in `results/images/`)**
âœ” **ROC Curves** â†’ `roc_curve.png`  
âœ” **Feature Importances** â†’ `feature_importance_RandomForestClassifier.png`  
âœ” **SHAP Explanation** â†’ `shap_RandomForestClassifier.png`

### âœ… **Stored Models (`models/` Directory)**
âœ” **Logistic Regression (`LogisticRegression.pkl`)**  
âœ” **Random Forest (`RandomForestClassifier.pkl`)**  

Models are stored in **.pkl format using Joblib** for easy deployment.

---

## ğŸ”¬ **Handling Categorical Variables**
- Uses **mean encoding** or **one-hot encoding** based on configuration  
- Efficiently processes categorical columns via **looping**  
- Defined in `src/data_preprocessing/data_encoder.py`

---

## ğŸ›  **Future Improvements**
âœ” **Optimize hyperparameter tuning strategy**  
âœ” **Enhance model versioning with MLflow**  
âœ” **Add Docker support for easy deployment**  

---

## ğŸ‘¨â€ğŸ’¼ **Author**
**Marc Ennaji**  
ğŸŒ [GitHub](https://github.com/Marcennaji) | ğŸ“ [LinkedIn](https://linkedin.com/in/marcennaji)  

---

## ğŸ **License**
This project is licensed under the **MIT License**.  

